#!/usr/bin/env python3
"""
API Contract Extraction Script for Direct Replacement Refactoring

This script extracts API contracts and data models from existing frontend codebases
to ensure direct replacement compatibility during refactoring.

Usage:
    python3 scripts/extract-api-contracts.py --source <source_path> --output <output_file>
    python3 scripts/extract-api-contracts.py --source /path/to/angular/project --output api-contracts.md

Requirements:
    - Python 3.8+
    - Source code must be TypeScript/JavaScript frontend project
"""

import argparse
import json
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
from collections import defaultdict, Counter


@dataclass
class APIEndpoint:
    """APIç«¯ç‚¹å®šä¹‰"""
    method: str
    path: str
    description: str = ""
    source_file: str = ""
    line_number: int = 0
    api_type: str = "unknown"  # "backend" or "frontend"
    category: str = "unknown"  # "http", "service", "repository"


@dataclass
class InterfaceProperty:
    """æ¥å£å±æ€§å®šä¹‰"""
    name: str
    type: str
    optional: bool = False
    default_value: str = ""
    description: str = ""


@dataclass
class InterfaceDefinition:
    """TypeScriptæ¥å£å®šä¹‰"""
    name: str
    properties: List[InterfaceProperty]
    extends: List[str] = None
    source_file: str = ""
    line_number: int = 0
    description: str = ""
    
    def __post_init__(self):
        if self.extends is None:
            self.extends = []


@dataclass
class ComponentProps:
    """ç»„ä»¶å±æ€§å®šä¹‰"""
    component_name: str
    inputs: List[InterfaceProperty]
    outputs: List[InterfaceProperty]
    source_file: str = ""
    line_number: int = 0


class APIContractExtractor:
    """APIå¥‘çº¦æå–å™¨"""
    
    def __init__(self, source_path: Path):
        self.source_path = source_path
        self.api_endpoints: List[APIEndpoint] = []
        self.interfaces: Dict[str, InterfaceDefinition] = {}
        self.component_props: Dict[str, ComponentProps] = {}
        
        # TypeScriptè§£ææ¨¡å¼
        self.interface_pattern = re.compile(
            r'(?:export\s+)?(?:interface|type)\s+(\w+)(?:\s+extends\s+([^{]+))?\s*\{([^}]*)\}',
            re.MULTILINE | re.DOTALL
        )
        
        # å±æ€§è§£ææ¨¡å¼
        self.property_pattern = re.compile(
            r'(\w+)(\?)?:\s*([^;=\n]+)(?:\s*=\s*([^;\n]+))?',
            re.MULTILINE
        )
        
        # HTTPæ–¹æ³•æ¨¡å¼
        self.http_methods = ['get', 'post', 'put', 'delete', 'patch', 'head', 'options']
        
        # åç«¯APIè°ƒç”¨æ¨¡å¼ (çœŸå®HTTPè¯·æ±‚)
        self.backend_api_patterns = [
            r'\.(?:' + '|'.join(self.http_methods) + r')\([\'"`]([^\'"`]+)[\'"`]',
            r'request\([\'"`]([^\'"`]+)[\'"`]',
            r'fetch\([\'"`]([^\'"`]+)[\'"`]'
        ]
        
        # å‰ç«¯æœåŠ¡/ä»“åº“æ¨¡å¼
        self.frontend_service_patterns = [
            r'([A-Z][a-zA-Z]*Service)\.',
            r'([A-Z][a-zA-Z]*Repository)\.',
            r'([A-Z][a-zA-Z]*Api)\.',
            r'([a-zA-Z]*Service)\.',
            r'([a-zA-Z]*Repository)\.'
        ]
        
        # APIè·¯å¾„æ¨¡å¼
        self.api_path_patterns = [
            r'/api/[a-zA-Z0-9/_-]*',  # æ ‡å‡†APIè·¯å¾„
            r'/[a-zA-Z0-9/_-]*',       # å…¶ä»–è·¯å¾„
            r'http[s]?://[^\s\'"`]+'   # å®Œæ•´URL
        ]
    
    def extract_all(self) -> Dict[str, Any]:
        """æå–æ‰€æœ‰APIå¥‘çº¦"""
        print(f"ğŸ” æ­£åœ¨æå–APIå¥‘çº¦: {self.source_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰TypeScript/JavaScriptæ–‡ä»¶
        ts_files = list(self.source_path.rglob("*.ts")) + \
                   list(self.source_path.rglob("*.tsx")) + \
                   list(self.source_path.rglob("*.js")) + \
                   list(self.source_path.rglob("*.jsx"))
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(ts_files)} ä¸ªæºæ–‡ä»¶")
        
        for file_path in ts_files:
            self._extract_from_file(file_path)
        
        return {
            'api_endpoints': [asdict(ep) for ep in self.api_endpoints],
            'interfaces': {name: asdict(iface) for name, iface in self.interfaces.items()},
            'component_props': {name: asdict(props) for name, props in self.component_props.items()},
            'metadata': {
                'source_path': str(self.source_path),
                'extraction_date': datetime.now().isoformat(),
                'total_files': len(ts_files),
                'total_endpoints': len(self.api_endpoints),
                'total_interfaces': len(self.interfaces),
                'total_components': len(self.component_props)
            }
        }
    
    def _extract_from_file(self, file_path: Path):
        """ä»å•ä¸ªæ–‡ä»¶æå–ä¿¡æ¯"""
        try:
            content = file_path.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            # æå–æ¥å£å®šä¹‰
            self._extract_interfaces(content, str(file_path), lines)
            
            # æå–APIç«¯ç‚¹
            self._extract_api_endpoints(content, str(file_path), lines)
            
            # æå–ç»„ä»¶å±æ€§
            self._extract_component_props(content, str(file_path), lines)
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    def _extract_interfaces(self, content: str, file_path: str, lines: List[str]):
        """æå–TypeScriptæ¥å£å®šä¹‰"""
        matches = self.interface_pattern.finditer(content)
        
        for match in matches:
            interface_name = match.group(1)
            extends_str = match.group(2)
            properties_body = match.group(3)
            
            # è®¡ç®—è¡Œå·
            line_number = content[:match.start()].count('\n') + 1
            
            # è§£æç»§æ‰¿
            extends = []
            if extends_str:
                extends = [ext.strip() for ext in extends_str.split(',')]
            
            # è§£æå±æ€§
            properties = []
            for prop_match in self.property_pattern.finditer(properties_body):
                prop_name = prop_match.group(1)
                optional = prop_match.group(2) == '?'
                prop_type = prop_match.group(3).strip()
                default_value = prop_match.group(4).strip() if prop_match.group(4) else ""
                
                properties.append(InterfaceProperty(
                    name=prop_name,
                    type=prop_type,
                    optional=optional,
                    default_value=default_value
                ))
            
            # åˆ›å»ºæ¥å£å®šä¹‰
            interface = InterfaceDefinition(
                name=interface_name,
                properties=properties,
                extends=extends,
                source_file=file_path,
                line_number=line_number
            )
            
            self.interfaces[interface_name] = interface
    
    def _extract_api_endpoints(self, content: str, file_path: str, lines: List[str]):
        """æå–APIç«¯ç‚¹è°ƒç”¨"""
        
        # 1. æå–åç«¯API (çœŸå®HTTPè¯·æ±‚)
        for pattern in self.backend_api_patterns:
            matches = re.finditer(pattern, content)
            
            for match in matches:
                api_path = match.group(1) if len(match.groups()) > 0 else match.group(0)
                
                # è·³è¿‡ç›¸å¯¹è·¯å¾„å’ŒéAPIè·¯å¾„
                if not self._is_api_path(api_path):
                    continue
                
                # å°è¯•æ¨æ–­HTTPæ–¹æ³•
                method = self._infer_http_method(content, match.start(), lines)
                
                # è®¡ç®—è¡Œå·
                line_number = content[:match.start()].count('\n') + 1
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç«¯ç‚¹
                existing = None
                for ep in self.api_endpoints:
                    if ep.path == api_path and ep.api_type == "backend":
                        existing = ep
                        break
                
                if existing:
                    # æ›´æ–°ç°æœ‰ç«¯ç‚¹çš„HTTPæ–¹æ³•
                    if method and method not in existing.method:
                        existing.method += f",{method}"
                else:
                    # åˆ›å»ºåç«¯APIç«¯ç‚¹
                    endpoint = APIEndpoint(
                        method=method or "unknown",
                        path=api_path,
                        source_file=file_path,
                        line_number=line_number,
                        api_type="backend",
                        category="http"
                    )
                    self.api_endpoints.append(endpoint)
        
        # 2. æå–å‰ç«¯æœåŠ¡/ä»“åº“è°ƒç”¨
        for pattern in self.frontend_service_patterns:
            matches = re.finditer(pattern, content)
            
            for match in matches:
                service_name = match.group(1)
                
                # æå–æœåŠ¡æ–¹æ³•è°ƒç”¨
                service_method_pattern = rf'{service_name}\.(\w+)\('
                method_matches = re.finditer(service_method_pattern, content)
                
                for method_match in method_matches:
                    method_name = method_match.group(1)
                    
                    # æ„é€ å‰ç«¯APIè·¯å¾„
                    api_path = f"{service_name}.{method_name}"
                    
                    # è®¡ç®—è¡Œå·
                    line_number = content[:method_match.start()].count('\n') + 1
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç«¯ç‚¹
                    existing = None
                    for ep in self.api_endpoints:
                        if ep.path == api_path and ep.api_type == "frontend":
                            existing = ep
                            break
                    
                    if not existing:
                        # åˆ›å»ºå‰ç«¯APIç«¯ç‚¹
                        endpoint = APIEndpoint(
                            method="FRONTEND",
                            path=api_path,
                            description=f"Frontend service method call",
                            source_file=file_path,
                            line_number=line_number,
                            api_type="frontend",
                            category="service"
                        )
                        self.api_endpoints.append(endpoint)
    
    def _is_api_path(self, path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºAPIè·¯å¾„"""
        if not path:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…APIè·¯å¾„æ¨¡å¼
        for pattern in self.api_path_patterns:
            if re.match(pattern, path):
                return True
        
        return False
    
    def _infer_http_method(self, content: str, pos: int, lines: List[str]) -> str:
        """æ¨æ–­HTTPæ–¹æ³•"""
        # æŸ¥æ‰¾é™„è¿‘çš„HTTPæ–¹æ³•è°ƒç”¨
        line_start = content.rfind('\n', 0, pos)
        line_end = content.find('\n', pos)
        
        if line_start == -1:
            line_start = 0
        if line_end == -1:
            line_end = len(content)
        
        current_line = content[line_start:line_end]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«HTTPæ–¹æ³•
        for method in self.http_methods:
            if f'.{method}(' in current_line:
                return method.upper()
        
        return ""
    
    def _extract_component_props(self, content: str, file_path: str, lines: List[str]):
        """æå–ç»„ä»¶å±æ€§å®šä¹‰"""
        # æŸ¥æ‰¾@Componentæˆ–ç±»ä¼¼çš„è£…é¥°å™¨
        component_pattern = re.compile(
            r'@Component\s*\(\s*\{[^}]*selector\s*:\s*[\'"`]([^\'"`]+)[\'"`][^}]*\}',
            re.MULTILINE | re.DOTALL
        )
        
        # æŸ¥æ‰¾@Inputå’Œ@Outputè£…é¥°å™¨
        input_pattern = re.compile(r'@Input\(\)\s*(\w+)')
        output_pattern = re.compile(r'@Output\(\)\s*(\w+)')
        
        component_matches = component_pattern.finditer(content)
        
        for comp_match in component_matches:
            selector = comp_match.group(1)
            
            # æŸ¥æ‰¾ç»„ä»¶ç±»å
            class_match = re.search(r'export\s+class\s+(\w+)', content[comp_match.end():])
            if not class_match:
                continue
                
            component_name = class_match.group(1)
            
            # æå–Inputå’ŒOutputå±æ€§
            inputs = []
            outputs = []
            
            # åœ¨æ•´ä¸ªæ–‡ä»¶ä¸­æŸ¥æ‰¾è¯¥ç»„ä»¶çš„Input/Output
            component_section = content[comp_match.start():]
            
            for input_match in input_pattern.finditer(component_section):
                prop_name = input_match.group(1)
                # å°è¯•æ‰¾åˆ°å±æ€§ç±»å‹
                prop_type = self._find_property_type(component_section, prop_name)
                inputs.append(InterfaceProperty(
                    name=prop_name,
                    type=prop_type,
                    optional=True  # Angular Inputé»˜è®¤å¯é€‰
                ))
            
            for output_match in output_pattern.finditer(component_section):
                prop_name = output_match.group(1)
                # Outputé€šå¸¸æ˜¯EventEmitter
                outputs.append(InterfaceProperty(
                    name=prop_name,
                    type="EventEmitter<any>",
                    optional=True
                ))
            
            if inputs or outputs:
                line_number = content[:comp_match.start()].count('\n') + 1
                props = ComponentProps(
                    component_name=component_name,
                    inputs=inputs,
                    outputs=outputs,
                    source_file=file_path,
                    line_number=line_number
                )
                
                self.component_props[component_name] = props
    
    def _find_property_type(self, content: str, prop_name: str) -> str:
        """æŸ¥æ‰¾å±æ€§ç±»å‹"""
        # æŸ¥æ‰¾å±æ€§å®šä¹‰
        prop_pattern = re.compile(f'{prop_name}\\s*:\\s*([^;\\n]+)')
        match = prop_pattern.search(content)
        
        if match:
            return match.group(1).strip()
        
        return "any"


def generate_data_models_report(extracted_data: Dict[str, Any]) -> str:
    """ç”Ÿæˆæ•°æ®æ¨¡å‹ä¸“ç”¨æŠ¥å‘Š"""
    metadata = extracted_data['metadata']
    
    report = f"""# æ•°æ®æ¨¡å‹æå–æŠ¥å‘Š

**æºè·¯å¾„**: {metadata['source_path']}  
**æå–æ—¥æœŸ**: {metadata['extraction_date']}  
**æ–‡ä»¶æ€»æ•°**: {metadata['total_files']}  
**æ¥å£å®šä¹‰æ•°**: {metadata['total_interfaces']}  
**ç»„ä»¶å±æ€§æ•°**: {metadata['total_components']}

---

## 1. TypeScriptæ¥å£å¥‘çº¦

### æ¥å£æ¦‚è§ˆ

| æ¥å£å | å±æ€§æ•°é‡ | ç»§æ‰¿è‡ª | æºæ–‡ä»¶ | è¡Œå· |
|--------|----------|--------|--------|------|
"""
    
    # æ·»åŠ æ¥å£æ¦‚è§ˆè¡¨æ ¼
    for interface_name, interface in extracted_data['interfaces'].items():
        prop_count = len(interface['properties'])
        extends = ', '.join(interface['extends']) if interface['extends'] else '-'
        source_file = Path(interface['source_file']).name
        report += f"| {interface_name} | {prop_count} | {extends} | {source_file} | {interface['line_number']} |\n"
    
    report += "\n---\n\n## 2. è¯¦ç»†æ¥å£å®šä¹‰\n\n"
    
    # æ·»åŠ æ¥å£è¯¦ç»†å®šä¹‰
    for interface_name, interface in extracted_data['interfaces'].items():
        report += f"### {interface_name}\n\n"
        report += f"**æºæ–‡ä»¶**: {Path(interface['source_file']).name}:{interface['line_number']}\n\n"
        
        if interface['extends']:
            report += f"**ç»§æ‰¿**: {', '.join(interface['extends'])}\n\n"
        
        report += "| å±æ€§å | ç±»å‹ | å¯é€‰ | é»˜è®¤å€¼ |\n"
        report += "|--------|------|------|--------|\n"
        
        for prop in interface['properties']:
            optional_str = "æ˜¯" if prop['optional'] else "å¦"
            default_str = prop['default_value'] or "-"
            report += f"| {prop['name']} | {prop['type']} | {optional_str} | {default_str} |\n"
        
        report += "\n"
    
    # æ·»åŠ ç»„ä»¶å±æ€§
    if extracted_data['component_props']:
        report += "---\n\n## 3. ç»„ä»¶å±æ€§å¥‘çº¦\n\n"
        
        for component_name, props in extracted_data['component_props'].items():
            if props['inputs'] or props['outputs']:
                report += f"### {component_name}\n\n"
                report += f"**æºæ–‡ä»¶**: {Path(props['source_file']).name}:{props['line_number']}\n\n"
                
                if props['inputs']:
                    report += "#### Inputå±æ€§\n\n"
                    report += "| å±æ€§å | ç±»å‹ | å¯é€‰ |\n"
                    report += "|--------|------|------|\n"
                    
                    for inp in props['inputs']:
                        optional_str = "æ˜¯" if inp['optional'] else "å¦"
                        report += f"| {inp['name']} | {inp['type']} | {optional_str} |\n"
                    
                    report += "\n"
                
                if props['outputs']:
                    report += "#### Outputå±æ€§\n\n"
                    report += "| å±æ€§å | ç±»å‹ |\n"
                    report += "|--------|------|\n"
                    
                    for outp in props['outputs']:
                        report += f"| {outp['name']} | {outp['type']} |\n"
                    
                    report += "\n"
    
    report += "---\n\n## 4. é‡æ„åˆè§„æ€§æ£€æŸ¥\n\n"
    report += "### âœ… æ•°æ®æ¨¡å‹é‡æ„åˆè§„æ€§è¦æ±‚\n\n"
    report += "- [ ] **æ¥å£å®Œæ•´æ€§**: æ‰€æœ‰TypeScriptæ¥å£å·²æå–ï¼Œç¡®ä¿æ–°å‰ç«¯æ•°æ®ç»“æ„å®Œå…¨åŒ¹é…\n"
    report += "- [ ] **ç±»å‹ä¸€è‡´æ€§**: æ‰€æœ‰å±æ€§ç±»å‹å¿…é¡»ä¿æŒä¸€è‡´ï¼Œä¸¥ç¦ä¿®æ”¹æˆ–è‡ªå®šä¹‰å®šä¹‰\n"
    report += "- [ ] **ç»„ä»¶å±æ€§å…¼å®¹æ€§**: Angularç»„ä»¶å±æ€§å·²æå–ï¼Œç¡®ä¿Reactç»„ä»¶å¯¹åº”å®ç°\n"
    report += "- [ ] **æºä»£ç å¯è¿½æº¯æ€§**: æ‰€æœ‰æ¥å£éƒ½æ ‡æ³¨æºæ–‡ä»¶ä½ç½®ï¼Œä¾¿äºéªŒè¯\n"
    report += "- [ ] **æ— è‡ªå®šä¹‰å®šä¹‰**: ä¸¥ç¦åœ¨æ–°å‰ç«¯ä¸­è‡ªå®šä¹‰æ¥å£æˆ–æ•°æ®æ¨¡å‹\n"
    report += "- [ ] **100%æ•°æ®ä¿æŒ**: æ•°æ®æ¨¡å‹å¿…é¡»å®Œå…¨ä¿æŒï¼Œä»…UI/UXå¯ä¼˜åŒ–\n"
    
    return report


def generate_apis_report(extracted_data: Dict[str, Any]) -> str:
    """ç”ŸæˆAPIå¥‘çº¦ä¸“ç”¨æŠ¥å‘Š"""
    metadata = extracted_data['metadata']
    
    report = f"""# APIæ¥å£å¥‘çº¦æå–æŠ¥å‘Š

**æºè·¯å¾„**: {metadata['source_path']}  
**æå–æ—¥æœŸ**: {metadata['extraction_date']}  
**æ–‡ä»¶æ€»æ•°**: {metadata['total_files']}  
**APIç«¯ç‚¹æ•°**: {metadata['total_endpoints']}

---

## 1. HTTPç«¯ç‚¹å¥‘çº¦

| æ–¹æ³• | è·¯å¾„ | æºæ–‡ä»¶ | è¡Œå· |
|------|------|--------|------|
"""
    
    # æ·»åŠ APIç«¯ç‚¹è¡¨æ ¼
    for endpoint in extracted_data['api_endpoints']:
        report += f"| {endpoint['method']} | {endpoint['path']} | {Path(endpoint['source_file']).name} | {endpoint['line_number']} |\n"
    
    report += "\n---\n\n## 2. ç«¯ç‚¹åˆ†ç»„\n\n"
    
    # æŒ‰HTTPæ–¹æ³•åˆ†ç»„
    method_groups = {}
    for endpoint in extracted_data['api_endpoints']:
        method = endpoint['method']
        if method not in method_groups:
            method_groups[method] = []
        method_groups[method].append(endpoint)
    
    for method, endpoints in method_groups.items():
        report += f"### {method.upper()} ç«¯ç‚¹\n\n"
        for endpoint in endpoints:
            report += f"- `{endpoint['path']}` ({Path(endpoint['source_file']).name}:{endpoint['line_number']})\n"
        report += "\n"
    
    report += "---\n\n## 3. APIé‡æ„åˆè§„æ€§æ£€æŸ¥\n\n"
    report += "### âœ… APIå¥‘çº¦é‡æ„åˆè§„æ€§è¦æ±‚\n\n"
    report += "- [ ] **APIå®Œæ•´æ€§**: æ‰€æœ‰HTTPç«¯ç‚¹å·²æå–ï¼Œç¡®ä¿æ–°å‰ç«¯è°ƒç”¨ç›¸åŒæ¥å£\n"
    report += "- [ ] **æ–¹æ³•ä¸€è‡´æ€§**: æ‰€æœ‰HTTPæ–¹æ³•å¿…é¡»å®Œå…¨ä¸€è‡´ï¼Œä¸¥ç¦ä¿®æ”¹\n"
    report += "- [ ] **è·¯å¾„ç¨³å®šæ€§**: æ‰€æœ‰URLè·¯å¾„å¿…é¡»ä¿æŒç¨³å®šï¼Œç›´æ¥æ›¿æ¢æ— æ„ŸçŸ¥\n"
    report += "- [ ] **æºä»£ç å¯è¿½æº¯æ€§**: æ‰€æœ‰APIç«¯ç‚¹éƒ½æ ‡æ³¨æºæ–‡ä»¶ä½ç½®ï¼Œä¾¿äºéªŒè¯\n"
    report += "- [ ] **æ— é€‚é…å±‚**: æ–°å‰ç«¯å¿…é¡»ç›´æ¥è°ƒç”¨ç›¸åŒAPIï¼Œæ— éœ€é€‚é…å±‚\n"
    report += "- [ ] **100%è¡Œä¸ºä¿æŒ**: APIè°ƒç”¨è¡Œä¸ºå¿…é¡»å®Œå…¨ä¿æŒï¼Œä»…UI/UXå¯ä¼˜åŒ–\n"
    
    return report


def generate_markdown_report(extracted_data: Dict[str, Any]) -> str:
    """ç”ŸæˆMarkdownæ ¼å¼çš„APIå¥‘çº¦æŠ¥å‘Šï¼ˆç»¼åˆæŠ¥å‘Šï¼‰"""
    metadata = extracted_data['metadata']
    
    report = f"""# APIå¥‘çº¦æå–æŠ¥å‘Š

**æºè·¯å¾„**: {metadata['source_path']}  
**æå–æ—¥æœŸ**: {metadata['extraction_date']}  
**æ–‡ä»¶æ€»æ•°**: {metadata['total_files']}  
**APIç«¯ç‚¹æ•°**: {metadata['total_endpoints']}  
**æ¥å£å®šä¹‰æ•°**: {metadata['total_interfaces']}  
**ç»„ä»¶å±æ€§æ•°**: {metadata['total_components']}

---

## 1. APIç«¯ç‚¹ (HTTPæ¥å£å¥‘çº¦)

| æ–¹æ³• | è·¯å¾„ | æºæ–‡ä»¶ | è¡Œå· |
|------|------|--------|------|
"""
    
    # æ·»åŠ APIç«¯ç‚¹
    for endpoint in extracted_data['api_endpoints']:
        report += f"| {endpoint['method']} | {endpoint['path']} | {Path(endpoint['source_file']).name} | {endpoint['line_number']} |\n"
    
    report += "\n---\n\n## 2. æ•°æ®æ¨¡å‹ (TypeScriptæ¥å£å¥‘çº¦)\n\n"
    
    # æ·»åŠ æ¥å£å®šä¹‰
    for interface_name, interface in extracted_data['interfaces'].items():
        report += f"### {interface_name}\n\n"
        report += f"**æºæ–‡ä»¶**: {Path(interface['source_file']).name}:{interface['line_number']}\n\n"
        
        if interface['extends']:
            report += f"**ç»§æ‰¿**: {', '.join(interface['extends'])}\n\n"
        
        report += "| å±æ€§å | ç±»å‹ | å¯é€‰ | é»˜è®¤å€¼ |\n"
        report += "|--------|------|------|--------|\n"
        
        for prop in interface['properties']:
            optional_str = "æ˜¯" if prop['optional'] else "å¦"
            default_str = prop['default_value'] or "-"
            report += f"| {prop['name']} | {prop['type']} | {optional_str} | {default_str} |\n"
        
        report += "\n"
    
    report += "---\n\n## 3. ç»„ä»¶å±æ€§ (Angularç»„ä»¶å¥‘çº¦)\n\n"
    
    # æ·»åŠ ç»„ä»¶å±æ€§
    for component_name, props in extracted_data['component_props'].items():
        if props['inputs'] or props['outputs']:
            report += f"### {component_name}\n\n"
            report += f"**æºæ–‡ä»¶**: {Path(props['source_file']).name}:{props['line_number']}\n\n"
            
            if props['inputs']:
                report += "#### Inputå±æ€§\n\n"
                report += "| å±æ€§å | ç±»å‹ | å¯é€‰ |\n"
                report += "|--------|------|------|\n"
                
                for inp in props['inputs']:
                    optional_str = "æ˜¯" if inp['optional'] else "å¦"
                    report += f"| {inp['name']} | {inp['type']} | {optional_str} |\n"
                
                report += "\n"
            
            if props['outputs']:
                report += "#### Outputå±æ€§\n\n"
                report += "| å±æ€§å | ç±»å‹ |\n"
                report += "|--------|------|\n"
                
                for outp in props['outputs']:
                    report += f"| {outp['name']} | {outp['type']} |\n"
                
                report += "\n"
    
    report += "---\n\n## 4. é‡æ„åˆè§„æ€§æ£€æŸ¥\n\n"
    
    # ç”Ÿæˆåˆè§„æ€§æ£€æŸ¥æ¸…å•
    report += "### âœ… ç›´æ¥æ›¿æ¢é‡æ„åˆè§„æ€§è¦æ±‚\n\n"
    report += "- [ ] **APIå¥‘çº¦å®Œæ•´æ€§**: æ‰€æœ‰APIç«¯ç‚¹å·²æå–ï¼Œç¡®ä¿æ–°å‰ç«¯è°ƒç”¨ç›¸åŒæ¥å£\n"
    report += "- [ ] **æ•°æ®æ¨¡å‹ä¸€è‡´æ€§**: æ‰€æœ‰TypeScriptæ¥å£å·²æå–ï¼Œç¡®ä¿æ•°æ®ç»“æ„å®Œå…¨åŒ¹é…\n"
    report += "- [ ] **ç»„ä»¶å±æ€§å…¼å®¹æ€§**: Angularç»„ä»¶å±æ€§å·²æå–ï¼Œç¡®ä¿Reactç»„ä»¶å¯¹åº”å®ç°\n"
    report += "- [ ] **æºä»£ç å¯è¿½æº¯æ€§**: æ‰€æœ‰å¥‘çº¦éƒ½æ ‡æ³¨æºæ–‡ä»¶ä½ç½®ï¼Œä¾¿äºéªŒè¯\n"
    report += "- [ ] **æ— è‡ªå®šä¹‰å®šä¹‰**: ä¸¥ç¦åœ¨æ–°å‰ç«¯ä¸­è‡ªå®šä¹‰æ¥å£æˆ–æ•°æ®æ¨¡å‹\n"
    report += "- [ ] **100%è¡Œä¸ºä¿æŒ**: åŠŸèƒ½è¡Œä¸ºå¿…é¡»å®Œå…¨ä¿æŒï¼Œä»…UI/UXå¯ä¼˜åŒ–\n"
    
    report += "\n### âš ï¸ é‡è¦æé†’\n\n"
    report += "1. **ç›´æ¥æ›¿æ¢åŸåˆ™**: æ–°å‰ç«¯å¿…é¡»ç›´æ¥ä½¿ç”¨æå–çš„APIå¥‘çº¦ï¼Œä¸å¾—åˆ›å»ºé€‚é…å±‚\n"
    report += "2. **æ•°æ®çœŸå®æ€§**: ä¸¥ç¦ä½¿ç”¨å‡æ•°æ®ï¼Œå¿…é¡»è°ƒç”¨çœŸå®çš„åç«¯API\n"
    report += "3. **æ¥å£ç¨³å®šæ€§**: æ‰€æœ‰HTTPæ–¹æ³•å’ŒURLè·¯å¾„å¿…é¡»å®Œå…¨ä¸€è‡´\n"
    report += "4. **å±æ€§æ˜ å°„**: Angularçš„@Input/@Outputå¿…é¡»æ­£ç¡®æ˜ å°„åˆ°Reactç»„ä»¶props\n"
    
    return report


def generate_backend_apis_report(backend_apis: List[APIEndpoint], stats: dict) -> str:
    """ç”Ÿæˆåç«¯APIä¸“ç”¨æŠ¥å‘Š"""
    report = f"""# Backend REST API Contracts

**æå–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**APIç«¯ç‚¹æ€»æ•°**: {len(backend_apis)}

## ğŸ“Š æå–ç»Ÿè®¡

{generate_stats_table(stats)}

## ğŸ”— Backend APIç«¯ç‚¹è¯¦æƒ…

ä»¥ä¸‹ä¸ºçœŸå®çš„åç«¯HTTP APIæ¥å£è°ƒç”¨ï¼š

"""
    
    # æŒ‰HTTPæ–¹æ³•åˆ†ç»„
    by_method = defaultdict(list)
    for api in backend_apis:
        by_method[api.method].append(api)
    
    for method in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH']:
        if method in by_method:
            report += f"\n### {method} æ–¹æ³•\n\n"
            for api in sorted(by_method[method], key=lambda x: x.path):
                report += f"- **{api.path}**\n"
                if api.description:
                    report += f"  - æè¿°: {api.description}\n"
                report += f"  - ä½ç½®: {api.source_file}:{api.line_number}\n\n"
    
    # APIè·¯å¾„åˆ†æ
    paths = [api.path for api in backend_apis]
    if paths:
        report += "### ğŸ“ˆ APIè·¯å¾„åˆ†æ\n\n"
        
        # è·¯å¾„å‰ç¼€ç»Ÿè®¡
        prefixes = []
        for path in paths:
            parts = path.split('/')
            if len(parts) > 2:
                prefix = f"/{parts[1]}"
                prefixes.append(prefix)
        
        if prefixes:
            prefix_counts = Counter(prefixes)
            report += "#### APIè·¯å¾„å‰ç¼€åˆ†å¸ƒ\n"
            for prefix, count in prefix_counts.most_common():
                report += f"- **{prefix}**: {count} ä¸ªæ¥å£\n"
    
    return report


def generate_frontend_apis_report(frontend_apis: List[APIEndpoint], stats: dict) -> str:
    """ç”Ÿæˆå‰ç«¯APIä¸“ç”¨æŠ¥å‘Š"""
    report = f"""# Frontend TypeScript API Contracts

**æå–æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**APIæœåŠ¡æ€»æ•°**: {len(frontend_apis)}

## ğŸ“Š æå–ç»Ÿè®¡

{generate_stats_table(stats)}

## ğŸ”§ Frontend APIæœåŠ¡è¯¦æƒ…

ä»¥ä¸‹ä¸ºå‰ç«¯TypeScriptæœåŠ¡/ä»“å‚¨å±‚æ¥å£å®šä¹‰ï¼š

"""
    
    # æŒ‰æ–‡ä»¶åˆ†ç»„
    by_file = defaultdict(list)
    for api in frontend_apis:
        file_path = api.source_file
        # åªæ˜¾ç¤ºæ–‡ä»¶åï¼Œä¸æ˜¾ç¤ºå®Œæ•´è·¯å¾„
        file_name = Path(file_path).name
        by_file[file_name].append(api)
    
    for file_name, apis in by_file.items():
        report += f"\n### {file_name}\n\n"
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        by_category = defaultdict(list)
        for api in apis:
            by_category[api.category].append(api)
        
        for category in ['service', 'repository', 'unknown']:
            if category in by_category:
                category_name = {
                    'service': 'æœåŠ¡æ–¹æ³•',
                    'repository': 'ä»“å‚¨æ–¹æ³•',
                    'unknown': 'æœªåˆ†ç±»æ–¹æ³•'
                }[category]
                
                report += f"#### {category_name}\n"
                for api in sorted(by_category[category], key=lambda x: x.method):
                    report += f"- **{api.method}**()\n"
                    if api.description:
                        report += f"  - æè¿°: {api.description}\n"
                    report += f"  - ä½ç½®: ç¬¬{api.line_number}è¡Œ\n\n"
    
    # æœåŠ¡ç±»å‹ç»Ÿè®¡
    service_types = [api.category for api in frontend_apis]
    if service_types:
        report += "### ğŸ“Š æœåŠ¡ç±»å‹åˆ†å¸ƒ\n\n"
        type_counts = Counter(service_types)
        for service_type, count in type_counts.most_common():
            type_name = {
                'service': 'ServiceæœåŠ¡å±‚',
                'repository': 'Repositoryä»“å‚¨å±‚',
                'unknown': 'æœªåˆ†ç±»'
            }[service_type]
            report += f"- **{type_name}**: {count} ä¸ªæ–¹æ³•\n"
    
    return report


def generate_stats_table(stats: dict) -> str:
    """ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼"""
    table = "| æŒ‡æ ‡ | æ•°é‡ |\n"
    table += "|------|------|\n"
    table += f"| APIç«¯ç‚¹æ€»æ•° | {stats.get('total_endpoints', 0)} |\n"
    table += f"| æ¥å£å®šä¹‰æ•° | {stats.get('total_interfaces', 0)} |\n"
    table += f"| ç»„ä»¶å±æ€§æ•° | {stats.get('total_components', 0)} |\n"
    table += f"| æºæ–‡ä»¶æ•° | {stats.get('total_files', 0)} |\n"
    return table


def main():
    parser = argparse.ArgumentParser(description='Extract API contracts from frontend codebase')
    parser.add_argument('--source', required=True, help='Source code path')
    parser.add_argument('--output', required=True, help='Output markdown file path')
    parser.add_argument('--json', help='Also save JSON data to this file')
    parser.add_argument('--mode', choices=['combined', 'data-models', 'apis', 'backend-apis', 'frontend-apis'], default='combined',
                       help='Extraction mode: combined, data-models-only, apis-only, backend-apis-only, or frontend-apis-only')
    
    args = parser.parse_args()
    
    source_path = Path(args.source)
    output_path = Path(args.output)
    
    if not source_path.exists():
        print(f"âŒ æºè·¯å¾„ä¸å­˜åœ¨: {source_path}")
        return 1
    
    # åˆ›å»ºæå–å™¨
    extractor = APIContractExtractor(source_path)
    
    # æå–æ•°æ®
    extracted_data = extractor.extract_all()
    
    # æ ¹æ®æ¨¡å¼ç”ŸæˆæŠ¥å‘Š
    if args.mode == 'data-models':
        markdown_report = generate_data_models_report(extracted_data)
        print(f"âœ… æ•°æ®æ¨¡å‹æŠ¥å‘Šå·²ç”Ÿæˆ")
    elif args.mode == 'apis':
        markdown_report = generate_apis_report(extracted_data)
        print(f"âœ… APIå¥‘çº¦æŠ¥å‘Šå·²ç”Ÿæˆ")
    elif args.mode == 'backend-apis':
        # è¿‡æ»¤å‡ºåç«¯API
        backend_apis = [ep for ep in extractor.api_endpoints if ep.api_type == 'backend']
        stats = extracted_data['metadata']
        markdown_report = generate_backend_apis_report(backend_apis, stats)
        print(f"âœ… Backend APIæŠ¥å‘Šå·²ç”Ÿæˆ")
    elif args.mode == 'frontend-apis':
        # è¿‡æ»¤å‡ºå‰ç«¯API
        frontend_apis = [ep for ep in extractor.api_endpoints if ep.api_type == 'frontend']
        stats = extracted_data['metadata']
        markdown_report = generate_frontend_apis_report(frontend_apis, stats)
        print(f"âœ… Frontend APIæŠ¥å‘Šå·²ç”Ÿæˆ")
    else:  # combined
        markdown_report = generate_markdown_report(extracted_data)
        print(f"âœ… ç»¼åˆAPIå¥‘çº¦æŠ¥å‘Šå·²ç”Ÿæˆ")
    
    # ä¿å­˜æŠ¥å‘Š
    output_path.write_text(markdown_report, encoding='utf-8')
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
    
    # ä¿å­˜JSONæ•°æ®ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.json:
        json_path = Path(args.json)
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(extracted_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSONæ•°æ®å·²ä¿å­˜: {json_path}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    metadata = extracted_data['metadata']
    print(f"\nğŸ“Š æå–ç»Ÿè®¡:")
    print(f"   - APIç«¯ç‚¹: {metadata['total_endpoints']}")
    print(f"   - æ¥å£å®šä¹‰: {metadata['total_interfaces']}")
    print(f"   - ç»„ä»¶å±æ€§: {metadata['total_components']}")
    
    return 0


if __name__ == '__main__':
    exit(main())